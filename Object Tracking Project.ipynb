{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02535118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e259c785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'ByteTrack'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ifzhang/ByteTrack.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a35c9367",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'supervision'...\n",
      "'python3' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'source' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "ERROR: File \"setup.py\" or \"setup.cfg\" not found. Directory cannot be installed in editable mode: C:\\Users\\Aselsan\\Desktop\\YOLO+BYTETrack\n",
      "ERROR: File \"setup.py\" or \"setup.cfg\" not found. Directory cannot be installed in editable mode: C:\\Users\\Aselsan\\Desktop\\YOLO+BYTETrack\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/roboflow/supervision.git\n",
    "!cd supervision\n",
    "\n",
    "# setup python environment and activate it\n",
    "!python3 -m venv venv\n",
    "!source venv/bin/activate\n",
    "\n",
    "# headless install\n",
    "!pip install -e \".\"\n",
    "\n",
    "# desktop install\n",
    "!pip install -e \".[desktop]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1623fe17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'ultralytics'...\n",
      "ERROR: File \"setup.py\" or \"setup.cfg\" not found. Directory cannot be installed in editable mode: C:\\Users\\Aselsan\\Desktop\\YOLO+BYTETrack\n"
     ]
    }
   ],
   "source": [
    "# Clone the ultralytics repository\n",
    "!git clone https://github.com/ultralytics/ultralytics\n",
    "\n",
    "# Navigate to the cloned directory\n",
    "!cd ultralytics\n",
    "\n",
    "# Install the package in editable mode for development\n",
    "!pip install -e .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd765a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb00703",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd543098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5990ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "# import dependencies\n",
    "from IPython.display import display, Javascript, Image\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode, b64encode\n",
    "import PIL\n",
    "import io\n",
    "import html\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import supervision as sv\n",
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "import tensorflow as tf\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917f67a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8m.pt') # You can choose either 'yolov8#' #--> 'n,s,l,x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d8f153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the input & output path\n",
    "input_video_path = \"/content/drive/MyDrive/inputs/football.mp4\"\n",
    "output_video_path = \"/content/drive/MyDrive/outputs/real_time_.mp4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822b3bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#created video capture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Get video properties (frame width, frame height, frame rate, etc.)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b218fdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you already have a video capture object 'cap'\n",
    "frame_width = cap.get(3)\n",
    "frame_height = cap.get(4)\n",
    "\n",
    "print(f\"Input frame size: {frame_width}x{frame_height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828bb3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the codec and initialize the video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # You can choose other codecs as needed\n",
    "desired_fps = 6\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, desired_fps, (640, 480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09bf7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "\n",
    "# JavaScript to properly create our live video stream using our webcam as input\n",
    "def video_stream():\n",
    "  js = Javascript('''\n",
    "    var video;\n",
    "    var div = null;\n",
    "    var stream;\n",
    "    var captureCanvas;\n",
    "    var imgElement;\n",
    "    var labelElement;\n",
    "\n",
    "    var pendingResolve = null;\n",
    "    var shutdown = false;\n",
    "\n",
    "    function removeDom() {\n",
    "       stream.getVideoTracks()[0].stop();\n",
    "       video.remove();\n",
    "       div.remove();\n",
    "       video = null;\n",
    "       div = null;\n",
    "       stream = null;\n",
    "       imgElement = null;\n",
    "       captureCanvas = null;\n",
    "       labelElement = null;\n",
    "    }\n",
    "\n",
    "    function onAnimationFrame() {\n",
    "      if (!shutdown) {\n",
    "        window.requestAnimationFrame(onAnimationFrame);\n",
    "      }\n",
    "      if (pendingResolve) {\n",
    "        var result = \"\";\n",
    "        if (!shutdown) {\n",
    "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
    "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
    "        }\n",
    "        var lp = pendingResolve;\n",
    "        pendingResolve = null;\n",
    "        lp(result);\n",
    "      }\n",
    "    }\n",
    "\n",
    "    async function createDom() {\n",
    "      if (div !== null) {\n",
    "        return stream;\n",
    "      }\n",
    "\n",
    "      div = document.createElement('div');\n",
    "      div.style.border = '2px solid black';\n",
    "      div.style.padding = '3px';\n",
    "      div.style.width = '100%';\n",
    "      div.style.maxWidth = '600px';\n",
    "      document.body.appendChild(div);\n",
    "\n",
    "      const modelOut = document.createElement('div');\n",
    "      modelOut.innerHTML = \"Status:\";\n",
    "      labelElement = document.createElement('span');\n",
    "      labelElement.innerText = 'No data';\n",
    "      labelElement.style.fontWeight = 'bold';\n",
    "      modelOut.appendChild(labelElement);\n",
    "      div.appendChild(modelOut);\n",
    "\n",
    "      video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      video.width = div.clientWidth - 6;\n",
    "      video.setAttribute('playsinline', '');\n",
    "      video.onclick = () => { shutdown = true; };\n",
    "      stream = await navigator.mediaDevices.getUserMedia(\n",
    "          {video: { facingMode: \"environment\"}});\n",
    "      div.appendChild(video);\n",
    "\n",
    "      imgElement = document.createElement('img');\n",
    "      imgElement.style.position = 'absolute';\n",
    "      imgElement.style.zIndex = 1;\n",
    "      imgElement.onclick = () => { shutdown = true; };\n",
    "      div.appendChild(imgElement);\n",
    "\n",
    "      const instruction = document.createElement('div');\n",
    "      instruction.innerHTML =\n",
    "          '' +\n",
    "          'When finished, click here or on the video to stop this demo';\n",
    "      div.appendChild(instruction);\n",
    "      instruction.onclick = () => { shutdown = true; };\n",
    "\n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      captureCanvas = document.createElement('canvas');\n",
    "      captureCanvas.width = 640; //video.videoWidth;\n",
    "      captureCanvas.height = 480; //video.videoHeight;\n",
    "      window.requestAnimationFrame(onAnimationFrame);\n",
    "\n",
    "      return stream;\n",
    "    }\n",
    "    async function stream_frame(label, imgData) {\n",
    "      if (shutdown) {\n",
    "        removeDom();\n",
    "        shutdown = false;\n",
    "        return '';\n",
    "      }\n",
    "\n",
    "      var preCreate = Date.now();\n",
    "      stream = await createDom();\n",
    "\n",
    "      var preShow = Date.now();\n",
    "      if (label != \"\") {\n",
    "        labelElement.innerHTML = label;\n",
    "      }\n",
    "\n",
    "      if (imgData != \"\") {\n",
    "        var videoRect = video.getClientRects()[0];\n",
    "        imgElement.style.top = videoRect.top + \"px\";\n",
    "        imgElement.style.left = videoRect.left + \"px\";\n",
    "        imgElement.style.width = videoRect.width + \"px\";\n",
    "        imgElement.style.height = videoRect.height + \"px\";\n",
    "        imgElement.src = imgData;\n",
    "      }\n",
    "\n",
    "      var preCapture = Date.now();\n",
    "      var result = await new Promise(function(resolve, reject) {\n",
    "        pendingResolve = resolve;\n",
    "      });\n",
    "      shutdown = false;\n",
    "\n",
    "      return {'create': preShow - preCreate,\n",
    "              'show': preCapture - preShow,\n",
    "              'capture': Date.now() - preCapture,\n",
    "              'img': result};\n",
    "    }\n",
    "    ''')\n",
    "\n",
    "\n",
    "  display(js)\n",
    "\n",
    "def video_frame(label, bbox):\n",
    "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e40c1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def js_to_frame(js_reply):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        js_reply: JavaScript object containing an image from the webcam\n",
    "    Returns:\n",
    "        frame: OpenCV BGR image\n",
    "    \"\"\"\n",
    "    # Decode base64 image\n",
    "    image_bytes = b64decode(js_reply.split(',')[1])\n",
    "    # Convert bytes to numpy array\n",
    "    jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
    "    # Decode numpy array into OpenCV BGR image\n",
    "    frame = cv2.imdecode(jpg_as_np, flags=1)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fc5ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_to_js(frame, quality=0.8):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        frame: OpenCV BGR image\n",
    "        quality: Quality for JPEG encoding (default is 0.8)\n",
    "    Returns:\n",
    "        js_reply: JavaScript object containing base64-encoded image data\n",
    "    \"\"\"\n",
    "    # Encode the frame as JPEG\n",
    "    _, buffer = cv2.imencode('.jpg', frame, [int(cv2.IMWRITE_JPEG_QUALITY), int(quality * 100)])\n",
    "\n",
    "    # Convert the buffer to bytes and then to base64\n",
    "    jpg_as_bytes = buffer.tobytes()\n",
    "    jpg_as_base64 = b64encode(jpg_as_bytes).decode('utf-8')\n",
    "\n",
    "    # Construct the JavaScript object\n",
    "    js_reply = 'data:image/jpeg;base64,' + jpg_as_base64\n",
    "\n",
    "    return js_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceea51a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_to_bytes(bbox_array):\n",
    "  \"\"\"\n",
    "  Params:\n",
    "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
    "  Returns:\n",
    "        bytes: Base64 image byte string\n",
    "  \"\"\"\n",
    "  # convert array into PIL image\n",
    "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
    "  iobuf = io.BytesIO()\n",
    "  # format bbox into png for return\n",
    "  bbox_PIL.save(iobuf, format='png')\n",
    "  # format return string\n",
    "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
    "  return bbox_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05da1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an object for drawing bboxes\n",
    "\n",
    "box_annotater = sv.BoxAnnotator(\n",
    "thickness=2,\n",
    "text_thickness=1,\n",
    "text_scale=1,\n",
    ")\n",
    "track_history = defaultdict(lambda: [])\n",
    "tracker = sv.ByteTrack() #init tracker object\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed016f14",
   "metadata": {},
   "source": [
    "## Input File - Output File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73902d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "while cap.isOpened(): #start input stream\n",
    "    ret, frame = cap.read() # read the video frame by frame\n",
    "\n",
    "    if not ret: # if there is not return value end the loop\n",
    "        break\n",
    "    results = model(frame)[0] #detect objects in the frame by using yolov8 model\n",
    "    detections = sv.Detections.from_yolov8(results) # save the detections detection object structure -> xyxy(bboxes), mask, confidance, class_id, track_id\n",
    "\n",
    "    detections = tracker.update_with_detections(detections=detections) #run the BYTETrack algorithm\n",
    "\n",
    "    labels = [\n",
    "         f\"id:{tracker_id} {model.model.names[class_id]} {confidence:0.2f}\"\n",
    "         for _, _, confidence, class_id, tracker_id\n",
    "         in detections\n",
    "     ] # create label text for bboxes\n",
    "\n",
    "    frame = box_annotater.annotate(scene=frame, detections=detections, labels=labels) # use the drawing object for draw bboxes with labels on the frame\n",
    "\n",
    "    out.write(frame) # write the output frame into output path\n",
    "\n",
    "\n",
    "cap.release() #release the resources\n",
    "out.release() #release the resources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c09b719",
   "metadata": {},
   "source": [
    "## Real-Time Input / Real-Time Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453109bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# start streaming video from webcam\n",
    "# show the final output streaming video to notebook\n",
    "video_stream()\n",
    "# label for video\n",
    "label_html = 'Capturing...'\n",
    "# initialze bounding box to empty\n",
    "bbox = ''\n",
    "count = 0\n",
    "while True:\n",
    "    js_reply = video_frame(label_html, bbox)\n",
    "    if not js_reply:\n",
    "        break\n",
    "\n",
    "    # convert JS response to OpenCV Image\n",
    "    frameq = js_to_frame(js_reply[\"img\"])\n",
    "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
    "    results = model(frameq)[0]\n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "    detections = tracker.update_with_detections(detections=detections)\n",
    "    labels = [\n",
    "         f\"id:{tracker_id} {model.model.names[class_id]} {confidence:0.2f}\"\n",
    "         for _, _, confidence, class_id, tracker_id\n",
    "         in detections\n",
    "     ] # create label text for bboxes\n",
    "    \n",
    "    # I can't pass the output frame into real time video stream so I did different approach \n",
    "    frame = box_annotater.annotate(scene=frameq, detections=detections, labels=labels)\n",
    "    for bbox in detections.xyxy:\n",
    "        x1, y1, x2, y2 = map(int, bbox)\n",
    "        bbox_array = cv2.rectangle(bbox_array, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
    "    # convert overlay of bbox into bytes\n",
    "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
    "    # update bbox so next frame gets new overlay\n",
    "    bbox = bbox_bytes\n",
    "\n",
    "cap.release() #release the resources\n",
    "out.release() #release the resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac08446",
   "metadata": {},
   "source": [
    "## Real-Time Input - File Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478a43ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# start streaming video from webcam\n",
    "# show the final output streaming video to notebook\n",
    "video_stream()\n",
    "# label for video\n",
    "label_html = 'Capturing...'\n",
    "# initialze bounding box to empty\n",
    "bbox = ''\n",
    "count = 0\n",
    "while True:\n",
    "    js_reply = video_frame(label_html, bbox)\n",
    "    if not js_reply:\n",
    "        break\n",
    "\n",
    "    # convert JS response to OpenCV Image\n",
    "    frameq = js_to_frame(js_reply[\"img\"])\n",
    "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
    "    results = model(frameq)[0] #detect objects in the frame by using yolov8 model\n",
    "    detections = sv.Detections.from_yolov8(results) # save the detections detection object structure -> xyxy(bboxes), mask, confidance, class_id, track_id\n",
    "\n",
    "    detections = tracker.update_with_detections(detections=detections)  #run the BYTETrack algorithm\n",
    "    labels = [\n",
    "         f\"id:{tracker_id} {model.model.names[class_id]} {confidence:0.2f}\"\n",
    "         for _, _, confidence, class_id, tracker_id\n",
    "         in detections\n",
    "     ] # create label text for bboxes\n",
    "\n",
    "    frame = box_annotater.annotate(scene=frameq, detections=detections, labels=labels)  # use the drawing object for draw bboxes with labels on the frame\n",
    "    out.write(frame) # write the output frame into output path\n",
    "\n",
    "cap.release() #release the resources\n",
    "out.release() #release the resources"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
